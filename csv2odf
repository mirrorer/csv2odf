#!/usr/bin/python
# -*- coding: utf-8 -*-

# csv2odf  v2.01
# Copyright (C) 2014 Larry Jordan <w322 at users.sourceforge.net>

'''Convert a csv file to odf, ods, html, xlsx,
 or docx format.  csv2odf is a command line tool that
 can convert a comma separated value (csv) file to an
 odf, ods, html, xlsx, or docx document that can be viewed
 in LibreOffice and other office productivity
 programs. csv2odf is useful for creating reports from
 databases and other data sources that produce csv files.
 csv2odf can be combined with cron and shell scripts
 to automatically generate business reports.

 The output format (fonts, number formatting, etc.) is
 controlled by a template file that you design in
 LibreOffice.'''

# csv2odf is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# csv2odf is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

# Objects:
# Instance            Class
# --------            -----------------------
# app                 ApplicationController
# model               DocumentModel
# csv_merge_processor CSVMergeProcessor
# formula_adjuster    FormulaAdjustmentProcessor
# file_chunk_feeder   SequentialChunkFeeder
# string_file         SharedStringFile
# special_strings     SpecialStringSubstitutionProcessor
# zip                 DocumentArchive
# csv_data            IncomingDataSource

import getopt
import shlex
import sys
import os
import io
import zipfile
import tempfile
import itertools
import re
import xml.dom.minidom
import datetime
import cgi

class ApplicationController:

    VERSION = "2.01"

    # default properties
    quiet = 0             # show no output
    verbose = 0           # show extra output
    showhelp = 0          # display help text instead of processing document
    xml = 0               # return xml instead of a document
    div = 0               # for html files, the table uses <div> tags instead of <table>
    nodata = 0            # do not insert data into the document
    doctype = None        # the type of document to be processed
    start = 1             # begin at this row of the csv file (allows you to skip some rows)
    end = None            # end of this row of the csv file
    header_from_csv = 0   # insert the first row of the csv file as the header
    colSkips = 0          # the number of columns skipped in the column order
    rowSkips = 0          # number of rows at the top of document to skip over, header is the next row
    table = 1             # the table number where data will be inserted
    target_row = 2        # the row number where data will be inserted
    option_row_offset = 0 # integer to adjust table 1 when options are present
    delimiter = ","       # delimiter in csv file
    dateformat = ""       # the expected date format in csv data to convert to native format
    order = []            # column order list
    arguments = ""        # the command line argument string
    template_filename = "" # the name of the template file
    csv_filename = ""     # the name of the csv file
    out_filename = ""     # the name of the output file
    comment = ""          # comment string that might be inserted into the document
    debug = 0             # turn on extra debugging information

    def help(self):
        print("Usage: csv2odf [option] [<csvfile>] <templatefile> [<outputfile>]")
        print("")
        print("csv2odf is a command line tool that can convert a comma seperated value")
        print("(csv) file into an ods, odt, html, xlsx, or docx document.  csv2odf  is")
        print("useful  for creating reports from databases and other data sources that")
        print("produce csv files.  csv2odf can be combined with cron and shell scripts")
        print("to automatically generate business reports.")
        print("")
        print("The csv data is merged with a template file to produce the output file.")
        print("The template is a document file as produced  by  LibreOffice  or  Word,")
        print("or an html file.  The template can be a spreadsheet file (ods or xlsx),")
        print("a document file (odt or docx), or an html file.")
        print("")
        print("If a csv input file is not specified, input will be taken from standard")
        print("input  (stdin).   If  an  output  file is not specified, output will be")
        print("directed to standard output (stdout).  This allows the use of the  com-")
        print("mand in pipes.")
        print("")
        print("The  first row of the table will be treated as a header row.  (Override")
        print("with -H)  The formatting in the second row of cells will be applied  to")
        print("each data cell of the output file.")
        print("")
        print("If  the  template  is a spreadsheet, the second row should contain some")
        print("data of similar type to the incoming data  so  that  numbers/text/dates")
        print("can be correctly identified.")
        print("")
        print("If the template is a document, it must contain a  table  that  the  csv")
        print("data  will be inserted into.  If the first table in the file is not the")
        print("target, use the -t options to identify the table number.")
        print("")
        print("If the template is an html file, it must contain a table that  the  csv")
        print("data  will be inserted into.  If the first table in the file is not the")
        print("target, use the -t options to identify the table  number  or  table  id")
        print("property.  The table may be made using div tags if the --div options is")
        print("used, in which case a div tag must enclose each cell, each row, and the")
        print("entire table.")
        print("")
        print("In the header or footer of the template, you  can  insert  a  [csv2odf-")
        print("date]  tag  (\"csv2odf-date\" enclosed in square brackets).  The date tag")
        print("will be replaced by the current date.  The date format can  be  changed")
        print("using  format  codes  (see  below), for example [csv2odf-date %Y-%m-%d]")
        print("will produce a date like 2008-02-04.  A date with a day offset from the")
        print("current  date  can  be created by using +n or -n, for example [csv2odf-")
        print("date-1] would insert the date before today.")
        print("")
        print("The  options  may  be  placed  in  the  template file.  To do this, put")
        print("\"csv2odf:\" (without quotes) followed by the options in the  first  cell")
        print("(cell  A1).   Note  the  first  row  will  be  deleted when it contains")
        print("options.")
        print("")
        print("OPTIONS FOR PROCESSING CSV DATA FILE")
        print("-c <char>")
        print("       use char as delimiter instead of comma.  \\t will indicate a tab")
        print("       as the dilimiter.")
        print("")
        print("-o <spec>")
        print("       specify column order: 2,1,3 = second csv column  will  be  first")
        print("       column  in the output.  Also use to leave unchanged the contents")
        print("       of a template column: 1,2,,3,4 = the 3rd template column is  not")
        print("       overwritten.   Useful  if a column contains a formula.  The for-")
        print("       mula cell references will be offset to the correct row.")
        print("")
        print("-s <n> start reading at the nth row of the csv file")
        print("")
        print("-e <n> end reading at the nth row of the csv file")
        print("")
        print("-d <fmt>")
        print("       date format within csv data is specified by fmt string,  see  -D")
        print("       for  codes.   For  columns identified as dates, the program will")
        print("       attempt to translate incoming data into the native  date  coding")
        print("       using  the  format supplied with the -d option.  If the transla-")
        print("       tion fails, it data will be inserted as text.  In ods files, the")
        print("       program  knows  which columns are dates by looking for date for-")
        print("       matted cells in the template.  In xlsx files you must mark  date")
        print("       cells  with  the text [csv2odf-date] (csv2odf-date inside square")
        print("       brackets).")
        print("")
        print("OPTIONS FOR PROCESSING TEMPLATE FILE")
        print("-H     insert the first csv row into the header")
        print("")
        print("--comment=<text>")
        print("       replace [csv2odf-comment] within the document with <text>")
        print("")
        print("-S <n> skip  the  first n rows of the template file, the header will be")
        print("       the next row after those skipped")
        print("")
        print("-t <n> specify which tab or table to add data to, default first  table.")
        print("       For  html  files, -t may be followed by a name to match to table")
        print("       id property.")
        print("")
        print("--div  Search  for  <div>  tags  instead  of <table> (html files only).")
        print("       <div> tags must be nested with levels for table, row, and cell.")
        print("")
        print("--template-stdin-ods")
        print("       The template will be passed to std-in and it's  format  will  be")
        print("       ods")
        print("")
        print("--template-stdin-odt")
        print("       The  template  will  be passed to std-in and it's format will be")
        print("       odt")
        print("")
        print("--template-stdin-html")
        print("       The template will be passed to std-in and it's  format  will  be")
        print("       html")
        print("")
        print("--template-stdin-xlsx")
        print("       The  template  will  be passed to std-in and it's format will be")
        print("       xlsx")
        print("")
        print("--template-stdin-docx")
        print("       The template will be passed to std-in and it's  format  will  be")
        print("       docx")
        print("")
        print("GENERAL OPTIONS")
        print("-h     displays help information")
        print("")
        print("-v     verbose mode")
        print("")
        print("-D     show a list of date format codes (see below)")
        print("")
        print("-q     suppress all warning messages")
        print("")
        print("-x     create an xml output file instead of odf")
        print("")
        print("-n     do  not  merge the data into output, use with -x to extract tem-")
        print("       plate xml codes")
        print("")
        print("--input=<file>")
        print("       specify the csv data file location")
        print("")
        print("--template=<file>")
        print("       specify the tempate file location")
        print("")
        print("--output=<file>")
        print("       specify the output file location")
        print("")
        print("-V     display version number")
        print("")
        print("-z     display debugging information")

    def datehelp(self):
        '''Display codes for use with -d option'''
        print("These codes may be used with the -d option.")
        print("%a     Locale's abbreviated weekday name.")
        print("%A     Locale's full weekday name.")
        print("%b     Locale's abbreviated month name.")
        print("%B     Locale's full month name.")
        print("%c     Locale's appropriate date and time representation.")
        print("%d     Day of the month as a decimal number [01,31].")
        print("%H     Hour (24-hour clock) as a decimal number [00,23].")
        print("%I     Hour (12-hour clock) as a decimal number [01,12].")
        print("%j     Day of the year as a decimal number [001,366].")
        print("%m     Month as a decimal number [01,12].")
        print("%M     Minute as a decimal number [00,59].")
        print("%p     Locale's equivalent of either AM or PM.")
        print("%S     Second as a decimal number [00,61].")
        print("%U     Week number of the year (Sunday as the first day of the week)")
        print("          as a decimal number [00,53]. All days in a new year preceding")
        print("          the first Sunday are considered to be in week 0")
        print("%w     Weekday as a decimal number [0(Sunday),6].")
        print("%W     Week number of the year (Monday as the first day of the week)")
        print("          as a decimal number [00,53]. All days in a new year preceding")
        print("          the first Monday are considered to be in week 0.")
        print("%x     Locale's appropriate date representation.")
        print("%X     Locale's appropriate time representation.")
        print("%y     Year without century as a decimal number [00,99].")
        print("%Y     Year with century as a decimal number.")
        print("%Z     Time zone name (no characters if no time zone exists).")
        print('%%     A literal "%" character.')

    def stop(self, message="", errnum=0):
        '''Terminate the program with a message.'''
        if message:
            sys.stderr.write("csv2odf: " + message + "\n")
        sys.exit(errnum)

    def warning(self, message=""):
        '''Display a message and continue.'''
        if message:
            sys.stderr.write("csv2odf: " + message + "\n")

    def extension(self, string):
        '''Return the file type part of the file name.'''
        dot = string.rfind(".")
        if dot > 0:
            return string[dot+1:]
        else:
            return ""

    def int_minus_1(self, string):
        '''Converts a string to an integer and subtracts 1. '''
        if string:
            try:
                n = int(string)
            except ValueError:
                self.stop("Error: " + string + " does not look like a number ", 1)
            if n < 1:
                self.stop("Error: " + string + " cannot be less than 1 ", 1)
            return n - 1
        else:
            return None

    def get_args(self):
        '''get command line arguments'''
        self.arguments = sys.argv[1:]
        if self.arguments:
            self.parse_args(self.arguments)
        else:
            self.warning("No arguments provided, outputting help infomation.")
            self.help()
            sys.exit(0)

    def add_args(self, arguments):
        '''add arguments from file, however, command line arguments override these'''
        if arguments:
            self.parse_args(arguments)
            self.parse_args(self.arguments)  # command line arguments override

    def parse_args(self, arguments):
        '''parse an argument string'''
        EN_DASH = 'â€“'
        if isinstance(arguments, str):  # if arguments is a string, split it into a list.
            arguments = arguments.replace(EN_DASH, '--')  # openoffice may sometimes replace a double-dash with an en-dash (unicode 2013), change it to double-dash.
            arguments = shlex.split(arguments)
        elif sys.version_info[0] == 2 and isinstance(arguments, unicode):  # if arguments is a unicode string, split it into a list.
            arguments = arguments.replace(EN_DASH.decode('utf-8'), '--').encode()  # openoffice may sometimes replace a double-dash with an en-dash (unicode 2013), change it to double-dash.
            arguments = shlex.split(arguments)
        # else: arguments is alread a list, no action required
        try:
            optionlist, argumentlist = getopt.gnu_getopt(arguments, "hHqvxnVzs:t:e:c:Dd:S:o:",
                ["input=", "template=", "output=", "comment=", "div",
                    "template-stdin-ods", "template-stdin-odt", "template-stdin-html",
                    "template-stdin-xlsx", "template-stdin-docx"])
        except getopt.GetoptError:
            self.warning("Error processing arguments, outputting help infomation.")
            self.help()
            sys.exit(1)
        for o, a in optionlist:
            if o == "-h": self.showhelp = 1
            elif o == "-q": self.quiet = 1
            elif o == "-v": self.verbose = 1
            elif o == "-x": self.xml = 1
            elif o == "-n": self.nodata = 1
            elif o == "-c":
                if a == "\\t":
                    self.delimiter = "\t"
                else:
                    self.delimiter = a
            elif o == "-d": self.dateformat = a
            elif o == "-V":
                self.stop("version "+self.VERSION)
            elif o == "-o":
                self.order = list(map( self.int_minus_1, a.split(",") ))
                for i in range(len(self.order)):
                    if self.order[i] is None:
                        self.colSkips += 1
            elif o == "-D":
                self.warning("outputting help for date codes.")
                self.datehelp()
                sys.exit(0)
            elif o == "-H": self.header_from_csv = 1
            elif o == "-s":
                try:
                    self.start = int(a)
                except ValueError:
                    self.stop("Error: "+a+" does not look like a number", 1)
            elif o == "-S":
                try:
                    self.rowSkips = int(a)
                    self.target_row = self.rowSkips + 2
                except ValueError:
                    self.stop("Error: "+a+" does not look like a number", 1)
            elif o == "-t":
                try:
                    self.table = int(a)
                except ValueError:
                    self.table = a
            elif o == "-e":
                try:
                    self.end = int(a)
                except ValueError:
                    self.stop("Error: "+a+" does not look like a number", 1)
            elif o == "--input":
                self.csv_filename = a
                if self.extension(a) == 'tsv':
                    self.delimiter = "\t"
            elif o == "--template":
                self.template_filename = a
            elif o == "--output":
                self.out_filename = a
            elif o == "--comment":
                self.comment = a
            elif o == "--div":
                self.div = 1
            elif o == "--template-stdin-ods":
                self.template_filename = "stdin"
                self.doctype = "ods"
            elif o == "--template-stdin-odt":
                self.template_filename = "stdin"
                self.doctype = "odt"
            elif o == "--template-stdin-html":
                self.template_filename = "stdin"
                self.doctype = "html"
            elif o == "--template-stdin-xlsx":
                self.template_filename = "stdin"
                self.doctype = "xlsx"
            elif o == "--template-stdin-docx":
                self.template_filename = "stdin"
                self.doctype = "docx"
            elif o == "-z":
                self.debug = 1
            else:
                self.stop("Error: Unrecognized option "+o, 1)
        if self.showhelp:
            self.warning("Outputting help infomation.")
            self.help()
            if argumentlist and not self.quiet:
                self.warning("Warning: when help is displayed, no files are processsed")
            sys.exit(0)
        #parse and validate arguments
        for index, argument in enumerate(argumentlist):
            if self.extension(argument) in ('ods', 'odt', 'html', 'htm', 'xlsx', 'docx',
                'xlsm', 'docm', 'xltx', 'dotx', 'xltm', 'dotm'):
                if not self.template_filename:
                    self.template_filename = argument  # first argument
                    if not self.doctype:
                        self.doctype = self.extension(argument)
                    if self.doctype in ('html', 'htm'):
                        self.doctype = 'html'
                    if self.doctype in ('xlsm', 'xltx', 'xltm'):
                        self.doctype = 'xlsx'
                    if self.doctype in ('docm', 'dotx', 'dotm'):
                        self.doctype = 'docx'
                elif not self.out_filename:
                    self.out_filename = argument  # second argument
            elif self.extension(argument) in ('csv', 'tsv'):
                if not self.csv_filename:
                    self.csv_filename = argument
                    if self.extension(argument) == 'tsv':
                        self.delimiter = "\t"
                else:
                    self.stop("Error: expected one file of csv type, got more than one", 1)
            elif self.extension(argument) == 'xml':
                if not self.out_filename:
                    self.out_filename = argument
                    self.xml = 1
                    if self.verbose: self.warning("Producing xml output file")
            elif index == 2 and self.template_filename and self.csv_filename and not self.out_filename:
                #out_file has not been identified but both other files have, just use the 3rd argument
                self.out_filename = argument
        if not self.template_filename:
            self.stop("Error: could not identify the template file in the given arguments.", 1)
        if self.template_filename != "stdin" and not os.path.exists(self.template_filename):
            self.stop("Error: file was not found: "+self.template_filename, 1)
        if not self.out_filename:
            self.out_filename = "stdout"

    def test_args(self):
        '''Verify required arguments were provided'''
        if not self.csv_filename and not self.template_filename:
            self.stop("Error: neither csv file nor template file were specified", 1)
        if not self.csv_filename:
            self.csv_filename = "stdin"
        if self.csv_filename == "stdin" and self.template_filename == "stdin":
            self.stop("Error: both csv file and template file cannot come from stdin", 1)
        if not self.template_filename:
            self.stop("Error: template file was not specified", 1)
        if (not self.quiet
            and not (self.xml and not self.extension(self.template_filename) in ['html', 'htm'])
            and not self.out_filename == "stdout"
            and not self.template_filename == "stdin"
            and not (self.extension(self.template_filename) ==  self.extension(self.out_filename))
            and not (self.extension(self.template_filename) ==  'xltx' and self.extension(self.out_filename) == 'xlsx') # Office template files
            and not (self.extension(self.template_filename) ==  'xltm' and self.extension(self.out_filename) == 'xlsm')
            and not (self.extension(self.template_filename) ==  'dotx' and self.extension(self.out_filename) == 'docx')
            and not (self.extension(self.template_filename) ==  'dotm' and self.extension(self.out_filename) == 'docm')
            and not (self.extension(self.template_filename) in ['html', 'htm']
                and self.extension(self.out_filename) in ['html', 'htm']) ):
            self.warning("Warning: The template and output files should be of the same type. "
                + "(" + self.extension(self.template_filename) + ' vs ' + self.extension(self.out_filename)+")")
        if self.template_filename != "stdin" and not os.path.exists(self.template_filename):
            self.stop("Error: file was not found: "+self.template_filename, 1)
        if self.csv_filename != "stdin" and not os.path.exists(self.csv_filename):
            self.stop("Error: file was not found: "+self.csv_filename, 1)
        if (isinstance(self.table, str)
            and not self.template_filename == "stdin"
            and not self.extension(self.template_filename) in ['html', 'htm'] ):
            self.stop("Error: -t option must have a number for files of type " +
                self.extension(self.template_filename), 1)
        if not self.doctype and self.template_filename != "stdin":
            self.doctype = self.extension(self.template_filename)
        if self.doctype in ("ods", "odt", "xlsx", "docx"):
            pass
        elif self.doctype in ("html", "htm"):
            if self.div:
                self.doctype = "html-div"
            else:
                self.doctype = "html-table"
            self.xml = 1
        elif self.doctype in ("xlsm", "xltx", "xltm"):
            self.doctype = "xlsx" # process the same as xlsx
        elif self.doctype in ("docm", "dotx", "dotm"):
            self.doctype = "docx" # process the same as docx
        else:
            self.stop("Error: Could not identify the template file type.", 1)


    def __init__(self):
        self.get_args()

    # end class ApplicationController


class DocumentModel:
    '''Regular expressions used to identify parts of a document file'''
    
    document_type = None
    
    model = {
        'ods': {
            r'tag-regex': r'(<(office:document-content)[^>]*>)|(<table:table>|<table:table [^>]*>|<office:chart[^>]*>)|(<table:table-row>|<table:table-row [^>]*>|<table:table-header-row>|<table:table-header-row [^>]+>|<table:database-ranges[^>]*>|<table:shapes[^>]*>|<chart:chart [^>]*>)|(</table:table-row>|</table:table-header-row>|</table:database-ranges>|</table:shapes>|</chart:chart>)|(</table:table>|</office:chart>)',
            #               group 1, 2: namespace               group 3: table start                group 4: row start                                                                                                                                      group 5: row end                                                                        group 6: table end
            'table_regex': r'^table:table$',
            'table-name-attribname': 'table:name',
            'row-tagname': 'table:table-row',
            'row-prototype': '<table:table-row/>',
            'cell-regex': r'^table:table-cell$',                
            'cell-tagname': ['table:table-cell','table:database-range', 'draw:object'],
            'textnode-regex': r'^text:p$',
            'textnode-tagname': 'text:p',
            'formula-regex': r'^table:formula$',
            'formula-tagname': ['table:formula', 'table:target-range-address','draw:notify-on-update-of-ranges'],
            'value-attribname': 'office:value',
            'date-attribname': 'office:date-value',
            'chartref-regex': r'^draw:object$',
            'chartRefNotifyRange-regex': r'^draw:notify-on-update-of-ranges$',
            'chartRefLink-regex': r'^xlink:href$',
            'filter-regex': r'^table:database-ranges$',
            'inner_filename_regex': r'content.xml|Object [0-9]{1,3}/content.xml',
            'target_filename_regex': r'^content.xml'},
        
        'odt': {
            'tag-regex': r'(<(office:document-content)[^>]*>)|(<table:table>|<table:table [^>]*>)|(<table:table-row>|<table:table-row [^>]*>|<table:table-header-row>|<table:table-header-row [^>]+>)|(</table:table-row>|</table:table-header-row>)|(</table:table>)',
            'table_regex': r'^table:table$',
            'table-name-attribname': None,
            'row-regex': r'</{0,1}table:table-row[^>]*>|</{0,1}table:table-header-row[^>]*>',
            'row-tagname': 'table:table-row',
            'row-prototype': '<table:table-row/>',
            'cell-regex': r'^table:table-cell$',
            'cell-tagname': ['table:table-cell'],
            'textnode-regex': r'^text:p$',
            'textnode-tagname': 'text:p',
            'formula-regex': None,
            'formula-tagname': ['table:formula'],
            'value-attribname': 'office:value',
            'date-attribname': 'office:date-value',
            'chartref-regex': None,
            'chartRefNotifyRange-regex': None,
            'chartRefLink-regex': None,
            'filter-regex': None,
            'inner_filename_regex': r'content.xml',
            'target_filename_regex': r'content.xml' },
        
        'html-table': {
            'tag-regex': r'(<(html)[^>]*>)|(<table[^>]*>)|(<tr[^>]*>)|(</tr>)|(</table>)',
            'table_regex': r'^table$',
            'table-name-attribname': 'id',
            'row-tagname': 'tr',
            'row-prototype': '<tr/>',
            'cell-regex': r'^th$|^td$',
            'cell-tagname': ['td', 'th'],
            'textnode-regex': None,
            'textnode-tagname': None,
            'formula-regex': None,
            'formula-tagname': [],
            'value-attribname': None,
            'date-attribname': None,
            'chartref-regex': None,
            'chartRefNotifyRange-regex': None,
            'chartRefLink-regex': None,
            'filter-regex': None,
            'inner_filename_regex': None,
            'target_filename_regex': None },
        
        'html-div': {
            'tag-regex': r'(<(html)[^>]*>)|(<div[^>]*id=[^>]*>)|(<div[^>]*>)|(</div>)|(</div>)',
            'table_regex': r'^div$',
            'table-name-attribname': 'id',
            'row-tagname': 'div',
            'row-prototype': '<div/>',
            'cell-regex': r'^div$',
            'cell-tagname': ['div'],
            'textnode-regex': r'^div$',
            'textnode-tagname': 'div',
            'formula-regex': None,
            'formula-tagname': [],
            'value-attribname': None,
            'date-attribname': None,
            'chartref-regex': None,
            'chartRefNotifyRange-regex': None,
            'chartRefLink-regex': None,
            'filter-regex': None,
            'inner_filename_regex': None,
            'target_filename_regex': None },
        
        'xlsx': {
            'tag-regex': r'(<(worksheet|workbook |c:chartSpace)[^>]*>)|(<sheetData[^>]*>|<workbook [^>]*>|<c:lineChart>)|(<row[^/>]*>|<definedNames>|<c:ser>)|(</row>|</definedNames>|</c:ser>)|(</sheetData>|</workbook>|</c:lineChart>)',
            'table_regex': r'^sheetData$',
            'table-name-attribname': '',
            'row-tagname': 'row',
            'row-prototype': '<row/>',
            'cell-regex': r'^c$',
            'cell-tagname': ['c', 'c:numRef', 'definedName'],
            'textnode-regex': r'^v$',
            'textnode-tagname': 'v',
            'formula-regex': r'^f$',
            'formula-tagname': ['f'],
            'value-attribname': 'v',
            'date-attribname': None,
            'chartref-regex': None,
            'chartRefNotifyRange-regex': None,
            'chartRefLink-regex': None,
            'filter-regex': r'^autoFilter$',
            'inner_filename_regex': r"xl/worksheets/sheet[0-9]+\.xml|xl/sharedStrings\.xml|xl/workbook\.xml|xl/charts/chart[0-9]+\.xml",
            'target_filename_regex': r'xl/worksheets/sheet[0-9]+\.xml' },
        
        'docx': {
            'tag-regex': r'(<(w:document)[^>]*>)|(<w:tbl [^>]*>|<w:tbl>)|(<w:tr[^>]*>)|(</w:tr>)|(</w:tbl>)',
            'table_regex': r'^w:tbl$',
            'table-name-attribname': '',
            'row-tagname': 'w:tr',
            'row-prototype': '<w:tr/>',
            'cell-regex': r'^w:tc$',
            'cell-tagname': ['w:tc'],
            'textnode-regex': r'^w:t$',
            'textnode-tagname': 'w:t',
            'formula-regex': None,
            'formula-tagname': [],
            'value-attribname': None,
            'date-attribname': None,
            'chartref-regex': None,
            'chartRefNotifyRange-regex': None,
            'chartRefLink-regex': None,
            'filter-regex': None,
            'inner_filename_regex': r'word/document\.xml',
            'target_filename_regex': r'word/document\.xml'}
    }    
    
    def __init__(self, app):
        if app.doctype == 'html':
            if app.div:
                self.document_type = 'html-div'
            else:
                self.document_type = 'html-table'
        else:
            self.document_type = app.doctype
            
    def tag_regex(self):
        return self.model[self.document_type]['tag-regex']
    
    def table_regex(self):
        return self.model[self.document_type]['table_regex']

    def table_name_attrib_name(self):
        return self.model[self.document_type]['table-name-attribname']

    def row_tagname(self):
        return self.model[self.document_type]['row-tagname']

    def row_prototype(self):
        return self.model[self.document_type]['row-prototype']

    def cell_regex(self):
        return self.model[self.document_type]['cell-regex']

    def cell_tagname(self, index=None):
        if index:
            return self.model[self.document_type]['cell-tagname'][index]
        else:
            return self.model[self.document_type]['cell-tagname']

    def textnode_regex(self):
        return self.model[self.document_type]['textnode-regex']

    def textnode_tagname(self):
        return self.model[self.document_type]['textnode-tagname']

    def formula_regex(self):
        return self.model[self.document_type]['formula-regex']

    def formula_attribname(self):
        return self.model[self.document_type]['formula-tagname']
    
    def value_attribname(self):
        return self.model[self.document_type]['value-attribname']

    def date_attribname(self):
        return self.model[self.document_type]['date-attribname']

    def chartref_regex(self):
        return self.model[self.document_type]['chartref-regex']

    def chartRefNotifyRange_regex(self):
        return self.model[self.document_type]['chartRefNotifyRange-regex']

    def chartRefLink_regex(self):
        return self.model[self.document_type]['chartRefLink-regex']

    def filter_regex(self):
        return self.model[self.document_type]['filter-regex']

    def inner_filename_regex(self, file_num=1):
        return self.model[self.document_type]["inner_filename_regex"]

    def target_filename_regex(self, file_num=1):
        return self.model[self.document_type]["target_filename_regex"]

    # end class DocumentModel
    

class CSVMergeProcessor:
    '''This object takes a row of csv data and merges it with an xml template row.'''

    #properties
    app = None  # an application controller object
    model = None  # an object with document tag search strings
    formula_adjuster = None # an object that can adjust formula references
    template_document = "" # template as document object model
    template_elem = None # template row as document element
    inner_files = [] # a list of zip file objects
    string_file = None  # an object that handles the string file for xlsx
    table_name = "" # the tab name of the table
    last_row = 0 # the number of the last inserted data row
    xlsx_sheet_count = 0 # the number of sheet in an xlsx doc
    spool_max = 20e6 # max size of a temporary file before it is written to disk
    formula_attrib_name_list = None
    value_attrib_name = None
    doctype = 'odf'
    indexed_original_end = 0
    EPOCH = 693594 # ordinal equivalent of 1/1/1970

    def __init__(self, app, model):
        self.app = app
        self.model = model
        self.formula_adjuster = FormulaAdjustmentProcessor(app, model)
        self.formula_attrib_name_list = self.model.formula_attribname()
        self.value_attrib_name = self.model.value_attribname()
        self.date_attrib_name = self.model.date_attribname()

    def set_template(self, template):
        self.template_document = template
        self.template_elem = self.template_document.getElementsByTagName(self.model.row_tagname())[0]
    
    def set_string_file(self, string_file):
        self.string_file = string_file
        
    def set_num_insert_rows(self, num_insert_rows):
        self.formula_adjuster.num_insert_rows = num_insert_rows

    def dictionary_combine(self, dict1, dict2):
        return dict(itertools.chain(dict1.items(), dict2.items()))

    def merge_row(self, data_row, sheet_row_number, formula_offset, in_table_1, in_target_table, in_target_row=False):
        '''Inputs:
            data_row:        a list of csv data items
            sheet_row_number: the row number were the row will be placed
            formula_offset:  an integer that is added to formula cell addresses to adjust to added data row
           Output:           a row of xml cell with csv data merged into it'''
        if self.app.debug:
            sys.stderr.write("Sheet row: "+str(sheet_row_number)+"\n")
        output_row = self.template_elem.cloneNode(True)
        while output_row.childNodes.length > 0:
            output_row.removeChild(output_row.lastChild)
        i = 0
        if self.app.doctype == 'xlsx':
            if not output_row.hasAttribute('r'):                                                                      
                ref_node = self.template_document.createAttribute('r')
                output_row.setAttributeNode(ref_node)
            output_row.setAttribute('r', str(sheet_row_number))
        for node in self.template_elem.childNodes:
            new_node = node.cloneNode(True)
            if new_node.hasChildNodes() and re.match(self.model.cell_regex(), node.nodeName):
                if new_node.hasAttribute('table:number-columns-repeated'): # it's a compressed cell, expand it
                    number_columns_repeated = int(new_node.getAttribute('table:number-columns-repeated'))
                    new_node.removeAttribute('table:number-columns-repeated')
                    data_item = self.data_item_from_index(data_row, i)
                    merged_cell = self.merge_cell(new_node, data_item, sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table, in_target_row)
                    output_row.appendChild(merged_cell)
                    i += 1
                    for j in range(number_columns_repeated - 1):
                        additional_node = new_node.cloneNode(True)
                        data_item = self.data_item_from_index(data_row, i)
                        merged_cell = self.merge_cell(additional_node, data_item, sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table, in_target_row)
                        output_row.appendChild(merged_cell)
                        i += 1
                else:
                    data_item = self.data_item_from_index(data_row, i)
                    merged_cell = self.merge_cell(new_node, data_item, sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table, in_target_row)
                    output_row.appendChild(merged_cell)
                    i += 1
            else:
                while self.app.doctype == 'ods' and i < len(data_row): # there is more data than template cells, append unformatted cells
                    data_item = self.data_item_from_index(data_row, i)
                    new_row = self.create_cell_node(data_item, i+1, sheet_row_number, self.template_document, in_table_1, in_target_table)
                    output_row.appendChild(new_row)
                    i += 1
                output_row.appendChild(new_node) # this is where we reinsert the empty placeholder node
        while i < len(data_row): # there is more data than template cells, append unformatted cells
            data_item = self.data_item_from_index(data_row, i)
            output_row.appendChild(self.create_cell_node(data_item, i+1, sheet_row_number, self.template_document, in_table_1, in_target_table))
            i += 1
        return output_row

    def data_item_from_index(self, data_row, i, default=""):
        '''Given an index number (i), select a data item from a data row.
           But the one selected may be based on a sequence provided by the user (self.app.order).'''
        if i < len(self.app.order):
            data_column_index = self.app.order[i]
        else:  # i is beyond the length of self.app.order
            data_column_index = i
        if data_column_index is not None and data_column_index < len(data_row):
            data_item = data_row[data_column_index]
        else: # data_column_index is not within the length of data_row
            data_item = default
        if sys.version_info[0] == 2:
            data_item = data_item.decode('UTF-8')
        return data_item

    def merge_cell(self, template_cell, data_item, sheet_row_number, formula_offset, sheet, in_table_1, in_target_table, in_target_row=False):
        '''Inputs:
            template_cell     a single cell used as the template, formatting is copied
            data_item         a string that will replace the text payload in the template_cell
            sheet_row_number  the row number were the cell will be placed
            formula_offset    an integer that is added to formula cell addresses
           Output:
            output_cell '''
        if self.app.debug:
            sys.stderr.write(" in: " + template_cell.toxml()+"\n")
        if data_item is None:
            data_item = ""
        output_cell = template_cell.cloneNode(True)
        if self.app.doctype in ['ods', 'odt']:
            if output_cell.hasAttribute(self.date_attrib_name): # it's a date
                output_cell.setAttribute(self.date_attrib_name, self.format_date(data_item))
                output_cell.firstChild.firstChild.data = ""  # for a date, leave the cell text empty
            self.formula_adjuster.adjust_cell(output_cell, in_table_1, in_target_table, in_target_row, formula_offset)
            if output_cell.hasAttribute(self.value_attrib_name):
                output_cell.setAttribute(self.value_attrib_name, data_item)
            text_line_list = data_item.splitlines()
            paragraph = output_cell.firstChild
            paragraph_template = paragraph.cloneNode(True)
            if not text_line_list: text_line_list = [""]
            paragraph.firstChild.data = text_line_list[0]
            for text_line in text_line_list[1:]:
                last_paragraph = paragraph_template.cloneNode(True)
                last_paragraph.firstChild.data = text_line  # put the value in the cell text
                output_cell.appendChild(last_paragraph)
        elif self.app.doctype == 'xlsx':
            self.formula_adjuster.adjust_cell(output_cell, in_table_1, in_target_table, in_target_row, formula_offset)
            value_list = output_cell.getElementsByTagName('v')
            if value_list:
                cell_value = value_list[0]
                if output_cell.hasAttribute('t') and output_cell.getAttribute('t') == 's':  # it's a cell with a string
                    index = cell_value.firstChild.data
                    if self.string_file.is_a_date_cell(index):
                        cell_value.firstChild.data = self.format_date(data_item)
                        output_cell.removeAttribute('t')
                    else:
                        index = self.string_file.append(data_item)
                        cell_value.firstChild.data = index
                else:
                    cell_value.firstChild.data = data_item
        elif self.app.doctype in ['html-table', 'html-div']:
            text_line_list = data_item.splitlines()
            if not text_line_list: text_line_list = [""]
            output_cell.firstChild.data = text_line_list[0]
            for text_line in text_line_list[1:]:
                output_cell.appendChild(sheet.createElement("br"))
                output_cell.appendChild(sheet.createTextNode(text_line))
        elif self.app.doctype == 'docx':
            text_line_list = data_item.splitlines()
            if not text_line_list: text_line_list = [""]
            paragraph = output_cell.getElementsByTagName('w:p')[0]
            text_node = paragraph.getElementsByTagName('w:t')[0]
            paragraph_template = paragraph.cloneNode(True)
            text_node.firstChild.data = text_line_list[0]
            for text_line in text_line_list[1:]:
                last_paragraph = paragraph_template.cloneNode(True)
                text_node = last_paragraph.getElementsByTagName('w:t')[0]
                text_node.firstChild.data = text_line
                output_cell.appendChild(last_paragraph)
        else:
            self.app.stop("Error: document type '"+self.app.doctype+"' is not recognized in merge_cell.", 1)
        if self.app.debug:
            sys.stderr.write("out: " + output_cell.toxml()+"\n")
        return output_cell
    
    def adjust_row(self, row_dom, in_table_1, in_target_table, in_target_row=False, data_row_index=0):
        '''transfer to formula_adjuster to adjust the formulas in a row'''
        if row_dom.getElementsByTagName('chart:chart'):
            self.formula_adjuster.adjust_chart(row_dom)
        else:
            self.formula_adjuster.adjust_row(row_dom, in_table_1, in_target_table, in_target_row, data_row_index)
        
    def null_row(self, data_row, sheet_row_number, formula_offset, in_target_table):
        '''delete the values in the template because there is no data to insert.
           Inputs:
            sheet_row_number: the row number were the row will be placed
            formula_offset:  an integer that is added to formula cell addresses
           Output:           a row of xml cell with csv data merged into it'''
        if self.app.debug:
            sys.stderr.write("Data_row "+str(sheet_row_number)+"\n")
        output_row = self.template_elem.cloneNode(True)
        while output_row.childNodes.length > 0:
            output_row.removeChild(output_row.lastChild)
        if self.app.doctype == 'xlsx' and output_row.hasAttribute('r'):
            output_row.setAttribute('r', str(sheet_row_number))
        for node in self.template_elem.childNodes:
            new_node = node.cloneNode(True)
            if new_node.hasChildNodes() and re.match(self.model.cell_regex(), node.nodeName):
                if new_node.hasAttribute('table:number-columns-repeated'): # it's a compressed cell, expand it
                    number_columns_repeated = int(new_node.getAttribute('table:number-columns-repeated'))
                    new_node.removeAttribute('table:number-columns-repeated')
                    merged_cell = self.merge_cell(new_node, "", sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table)
                    output_row.appendChild(merged_cell)
                    for j in range(number_columns_repeated - 1):
                        additional_node = new_node.cloneNode(True)
                        merged_cell = self.merge_cell(additional_node, "", sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table)
                        output_row.appendChild(merged_cell)
                else:
                    merged_cell = self.merge_cell(new_node, "", sheet_row_number, formula_offset, self.template_document, in_table_1, in_target_table)
                    output_row.appendChild(merged_cell)
            else:
                output_row.appendChild(new_node) # this is where we reinsert the empty placeholder node
        return output_row

    def format_date(self, date_in):
        '''reformat a date string to a standard format'''
        if len(self.app.dateformat) > 0:
            try:
                date = datetime.datetime.strptime(date_in, self.app.dateformat)
            except ValueError:
                self.app.stop("The date format"+" ["+self.app.dateformat+"] "+"could not be interpreted for data: "+date_in, 1)
            if self.app.doctype == 'xlsx':
                return str(date.toordinal() - self.EPOCH + 1.0*date.time().hour/24 + 1.0*date.time().minute/1440)
            else:
                return date.strftime('%Y-%m-%dT%H:%M:%S')
        else:  # if no format string is provided, we assusme the data is already in the correct format.
            return date_in

    def create_cell_node(self, data_string, column_number, row_number, content, in_table_1, in_target_table):
        new_cell_node = content.createElement(self.model.cell_tagname(0)[0])
        if self.app.doctype == 'xlsx':
            if self.model.textnode_regex() is None:
                new_cell_node.appendChild(content.createTextNode(data_string))
            else:
                new_text_node = content.createElement(self.model.textnode_tagname())
                new_text_node.appendChild(content.createTextNode(data_string))
                new_cell_node.appendChild(new_text_node)
            new_cell_node.setAttribute('t', 's')
            new_cell_node.setAttribute('r', self.column_letter(column_number)+str(row_number))
            new_cell_node = self.merge_cell(new_cell_node, data_string, row_number, 0, content, in_table_1, in_target_table)
        else:
            if self.model.textnode_regex() is None:
                new_cell_node.appendChild(content.createTextNode(data_string))
            else:
                data_list = data_string.splitlines()
                for data_item in data_list:
                    new_text_node = content.createElement(self.model.textnode_tagname())
                    new_text_node.appendChild(content.createTextNode(data_item))
                    new_cell_node.appendChild(new_text_node)
        return new_cell_node

    def column_letter(self, n):
        LETTER = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        if n > 18226:
            app.stop("Error: Cannot handle more than 18226 columns", 1)
        first_index = (n-1) // 702 - 1
        second_index = ((n-1) % 702) // 26 - 1
        third_index = (n-1) % 26
        if first_index >= 0:
            first_letter = LETTER[first_index]
            second_letter = LETTER[second_index + 1]
        else:
            first_letter = ""
            if second_index >= 0:
                second_letter = LETTER[second_index]
            else:
                second_letter = ""
        if third_index >= 0:
            third_letter = LETTER[third_index]
        else:
            third_letter = ""
        return "".join([first_letter, second_letter, third_letter])

    # end class CSVMergeProcessor


class FormulaAdjustmentProcessor:
    '''adjust formlas to point correctly to inserted data'''
    
    app = None               # application controller
    model = None             # an object with search patterns for the type of in_file being scanned
    enabled = True           # set to false to disable adjustments
    target_table_num = 1     # the table where data will be inserted
    target_table_name = None # table name with ! on end
    table_1_name = None      # the name of table 1
    num_insert_rows = 0      # the number of rows to be inserted
    formula_attrib_name = None # the name of the formaula attribute in the xml tag
    value_attrib_name = None # the name of the value attribute in the xml tag
    formula_regex = None     # compiled reges for formulas
    ODT_FORMULA_REGEX_STRING = r"<(~){0}(~){0}([a-zA-Z]{1,3})([0-9]+)(~){0}(~){0}(~){0}(~){0}>"
    XLSX_LOCATION_REGEX_STRING = r"([A-Z]*)([0-9]+)"
    FORMULA_REGEX_STRING =  r"(([a-zA-Z]+)[!\.]){0,1}(\${0,1}[a-zA-Z]{1,3}\${0,1})([0-9]+)(:(([a-zA-Z]+)[!\.]){0,1}(\${0,1}[a-zA-Z]{1,3}\${0,1})([0-9]+)){0,1}"
    #                           table name                    letter               number  : table name                   letter               number
    #               group:    1    2                            3                    4     5 6   7                          8                      9

    def __init__(self, app, model):
        self.app = app
        self.model = model
        self.target_table_num = self.app.table
        self.formula_regex = re.compile(self.FORMULA_REGEX_STRING)
        self.xlsx_location_regex = re.compile(self.XLSX_LOCATION_REGEX_STRING)
        self.formula_attrib_name_list = self.model.formula_attribname()
        self.value_attrib_name = self.model.value_attribname()
        if app.doctype == 'odt':
            self.formula_regex = re.compile(self.ODT_FORMULA_REGEX_STRING)
        else:
            self.formula_regex = re.compile(self.FORMULA_REGEX_STRING)
        
    def set_target_table_name(self, name):
        self.target_table_name = name
    
    def set_num_insert_rows(self, num_insert_rows):
        self.num_insert_rows = num_insert_rows
        
    def adjust_row(self, row_dom, in_table_1, in_target_table, in_target_row=False, data_row_index=0):
        '''locate the cells in each row and adjust formulas.'''
        if self.enabled:
            if self.app.doctype == 'xlsx':
                self.adjust_xlsx_location(row_dom.firstChild.firstChild, in_table_1, data_row_index)  # adjust the row tag
            for cell_tagname in self.model.cell_tagname():
                cell_list = row_dom.getElementsByTagName(cell_tagname)
                for cell in cell_list:
                    self.adjust_cell(cell, in_table_1, in_target_table, in_target_row, data_row_index)
                    
    def adjust_cell(self, cell_dom, in_table_1, in_target_table, in_target_row=False, data_row_index=0):
        '''if cell has formula, send for adjustment, clear other attributes so cell will be recalculated.'''
        if self.enabled:
            if self.app.doctype == 'xlsx':
                has_formula = False
                for child in cell_dom.childNodes:
                    if isinstance(child, xml.dom.minidom.Element) and  child.tagName in ['f', 'c:f']:
                        if child.hasChildNodes():
                            has_formula = True
                            formula = child.firstChild.data
                            formula = self.adjust_formula(formula, in_table_1, in_target_table, in_target_row, data_row_index)
                            child.firstChild.data = formula
                        if child.hasAttribute("ref"):
                            has_formula = True
                            formula = child.getAttribute("ref")
                            formula = self.adjust_formula(formula, in_table_1, in_target_table, in_target_row, data_row_index)
                            child.setAttribute("ref", formula)
                    elif isinstance(child, xml.dom.minidom.Text):  # this happens in data ranges in workbook.xml
                        formula = child.data
                        formula = self.adjust_formula(formula, in_table_1, in_target_table, in_target_row, data_row_index)
                        child.data = formula
                if has_formula:
                    for child in cell_dom.childNodes:
                        if child.tagName == 'v':
                            cell_dom.removeChild(child)
                self.adjust_xlsx_location(cell_dom, in_table_1, data_row_index)
            else:
                for formula_attrib_name in self.formula_attrib_name_list:
                    if cell_dom.hasAttribute(formula_attrib_name):
                        formula = cell_dom.getAttribute(formula_attrib_name)
                        formula = self.adjust_formula(formula, in_table_1, in_target_table, in_target_row, data_row_index)
                        cell_dom.setAttribute(formula_attrib_name, formula)
                        if cell_dom.hasAttribute(self.value_attrib_name):
                            cell_dom.setAttribute(self.value_attrib_name, "")  # clear value
            
    def adjust_formula(self, formula, in_table_1, in_target_table, in_target_row=False, data_row_index=0):
        # groups:
        # 1  tablename!
        # 2  tablename
        # 3  $A$
        # 4  1     (row_ref)
        # 5  :tablename!$B$2
        # 6  tablename!
        # 7  tablename
        # 8  $B$
        # 9  2     (range_end_ref)
        #
        # formula refers to              | action
        # ------------------------------ | -------------------
        # table 1                        | adjust if paramaters in first row
        # target table/before target row | no change
        # target table/target row        | if formula in target row: track, else: expand range
        # target table/after target row  | push down
        # other table                    | no change
        if self.enabled:
            new_formula = ""
            previous_match = 0
            param_adjust = 0
            for match in self.formula_regex.finditer(formula):
                if (match.group(2) is not None and match.group(2) == self.table_1_name) or (in_table_1 and match.group(1) is None):  # refers to table 1 - use option row offset
                    param_adjust = self.app.option_row_offset
                if (match.group(2) is not None and match.group(2) == self.target_table_name) or (in_target_table and match.group(1) is None):  # refers to target table
                    row_ref = int(match.group(4))
                    new_row_ref = row_ref + param_adjust
                    if new_row_ref == self.app.target_row and in_target_row:  # refers to target row and we are in target template (we are inserting data)
                        new_row_ref += data_row_index
                    elif new_row_ref > self.app.target_row:  # target points to self or after
                        new_row_ref += self.num_insert_rows - 1
                    if match.group(5):  # there is a range reference
                        range_end_ref = int(match.group(9))
                        new_range_end_ref = range_end_ref + param_adjust
                        if range_end_ref >= self.app.target_row:
                            add_insert_rows = self.num_insert_rows - 1  # target row already included, so subtract 1
                        else:
                            add_insert_rows = 0
                        if match.group(6):
                            new_range_end_ref = ''.join([':', match.group(6), match.group(8), str(new_range_end_ref + add_insert_rows)])
                        else:
                            new_range_end_ref = ''.join([':', match.group(8), str(new_range_end_ref + add_insert_rows)])
                    elif not in_target_row and new_row_ref == self.app.target_row and self.num_insert_rows > 0:  # expand reference into a range (was a single row ref, add range end ref)
                        new_range_end_ref = ''.join([":", match.group(3), str(row_ref + self.num_insert_rows - 1)])
                    else:
                        new_range_end_ref = ""
                    if match.group(1):
                        table_ref = match.group(1)
                    else:
                        table_ref = ""
                    if self.app.doctype == 'odt':
                        new_formula = ''.join([  
                            new_formula, 
                            formula[previous_match:match.start()],
                            table_ref,
                            '<',
                            match.group(3),
                            str(new_row_ref),
                            '>',
                            new_range_end_ref ])
                    else:
                        new_formula = ''.join([  
                            new_formula, 
                            formula[previous_match:match.start()],
                            table_ref,
                            match.group(3),
                            str(new_row_ref),
                            new_range_end_ref ])
                    previous_match = match.end()
                else:
                    new_formula = ''.join([ new_formula, formula[previous_match:match.end()] ])
                    previous_match = match.end()
            new_formula = ''.join([  
                new_formula, 
                formula[previous_match:] ])
            return new_formula
        else:
            return formula
    
    def adjust_chart(self, chart):
        '''Alter a chart so that cell references to the inserted data are correct.'''
        if self.enabled:
            chart_elements = chart.getElementsByTagName('chart:plot-area')
            chart_elements += chart.getElementsByTagName('chart:categories')
            chart_elements += chart.getElementsByTagName('chart:series')
            for chart_element in chart_elements:
                if chart_element.hasAttribute('table:cell-range-address'):
                    cell_address = chart_element.getAttribute('table:cell-range-address')
                    cell_address = self.adjust_formula(cell_address, False, False)  # charts are in a special object that cannot be either table 1 or target table
                    chart_element.setAttribute('table:cell-range-address', cell_address)
                if chart_element.hasAttribute('chart:values-cell-range-address'):
                    cell_address = chart_element.getAttribute('chart:values-cell-range-address')
                    cell_address = self.adjust_formula(cell_address, False, False)
                    chart_element.setAttribute('chart:values-cell-range-address', cell_address)
                if chart_element.hasAttribute('chart:label-cell-address'):
                    cell_address = chart_element.getAttribute('chart:label-cell-address')
                    cell_address = self.adjust_formula(cell_address, False, False)
                    chart_element.setAttribute('chart:label-cell-address', cell_address)
            chart_elements = chart.getElementsByTagName('svg:desc')
            for chart_element in chart_elements:
                cell_address = chart_element.firstChild.data
                cell_address = self.adjust_formula(cell_address, False, False)
                chart_element.firstChild.data = cell_address
            chart_elements = chart.getElementsByTagName('c:f')
            for chart_element in chart_elements:
                cell_address = chart_element.firstChild.data
                cell_address = self.adjust_formula(cell_address, False, False)
                chart_element.firstChild.data = cell_address
                
    def adjust_xlsx_location(self, cell_dom, in_table_1, data_row_index=0):
        if cell_dom.hasAttribute('r'):
            if in_table_1:  # refers to table 1 - use option row offset
                param_adjust = self.app.option_row_offset
            else:
                param_adjust = 0
            if (param_adjust + data_row_index) != 0:
                match = self.xlsx_location_regex.search(cell_dom.getAttribute('r'))
                col_letter = match.group(1)
                original_row_number = int(match.group(2))
                cell_dom.setAttribute('r', col_letter + str(original_row_number + param_adjust + data_row_index))
                
    # end class FormulaAdjustmentProcessor


class SequentialChunkFeeder:

    chunk_size = 4096   # the size of each chunk
    
    def feed(self, in_file, chunk_processor):
        '''read from an in_file and send arbitrary size chunks to a processor function
           Input: in_file - a file object
             chunk_processor - a function that accepts a chunk and optional end_of_file flag, 
                it returns a tuple of overlap string and keep_going flag.
        '''
        in_file.seek(0)
        overlap = ""
        # get a chunk
        if sys.version_info[0] == 2:
            new_chunk = str(in_file.read(self.chunk_size))
        else:
            new_chunk = in_file.read(self.chunk_size).decode('UTF-8')
        while new_chunk:
            chunk = ''.join([overlap, new_chunk])
            # process chunk
            overlap, keep_going = chunk_processor(chunk)
            if keep_going:  # get a new chunk
                if sys.version_info[0] == 2:
                    new_chunk = str(in_file.read(self.chunk_size))
                else:
                    new_chunk = in_file.read(self.chunk_size).decode('UTF-8')
            else:
                new_chunk = None
        # process the remaining string
        if keep_going and overlap:
            chunk_processor(overlap, end_of_file=True)
        
    # end class SequentialChunkFeeder
    

class DocumentProcessor:

    app = None          # an app controller object
    model = None        # an object with search patterns for the type of in_file being scanned
    file_chunk_feeder = None # an object that breaks a file into chunks and feeds to a processing function
    csv_data = None     # an iterator object returning rows of csv data
    csv_merge_processor = None # an object that can merge csv data into an xml template
    string_file = None  # an object that handles the string file for xlsx
    in_file_name = ""   # the name of the file being scanned
    special_strings = None # an object that can replace special string
    out_file = None     # a file object
    max_buffer = 20e6   # the maximum memory size used before the buffer is written to disk
    overlap_length = 64 # position within chunk to start overlap
    tag_regex = None    # a regular expression object
    namespace_start = "" # the namespace start tag string
    namespace_end = ""  # the namespace end tag string
    in_target_file = False # true when scanning target file
    target_table_num = None    # the table number we want to process
    target_table_name = None # the table tab name
    table_name_attrib_name = None # the name of the xml attribute containing table name
    table_index = {}    # a dictionary with table indexes and names for xlsx
    table_name = None   # a string table id attribute in html tables
    table_num = 0       # the number of tables found
    in_table_1 = False  # true when in first table
    seen_row_1 = False  # true after row 1 has been processed
    table_depth = 0     # count possible recursive tables
    row_depth = 0       # the levels of start/end tags was are in
    row_num = 0         # the row count within a table
    in_row = False      # set to true when inside a row
    row_string = ""     # accumulated row string used when a row crosses chunk boundary
    data_row_index = 0  # the csv data row number
    outgoing_data_row_index = 0 # the actual output data row index
    flush = False       # true when processing is complete and remainder of doc can be written out
    num_insert_rows = 0 # number of rows to be inserted from csv file
    cell_address_regex = None # regex object to septerate address components
    ods_table_name_regex = None # regex object to find table names in ods
    xlsx_special_regex = None # regex object to find xlsx autofilter and cell merge refs
    NAMESPACE = 1       # match group: document namespace tag
    NAMESPACE_TAGNAME = 2 # match group: document namespace tagname
    TABLESTART = 3      # match group: table start
    ROWSTART = 4        # match group: row start
    ROWEND = 5          # match group: row end
    TABLEEND = 6        # match group: table end
    
    def __init__(self, app, model, csv_merge_processor, special_strings):
        self.app = app
        self.model = model
        self.file_chunk_feeder = SequentialChunkFeeder()
        self.csv_merge_processor = csv_merge_processor
        self.special_strings = special_strings
        self.textnode_tagname = self.model.textnode_tagname()
        self.table_name_attrib_name = self.model.table_name_attrib_name()
        self.cell_address_regex = re.compile("([A-Z]+)([0-9]+)")
        #                                      letter  number
        self.ods_table_name_regex = re.compile('<table:table [^>]*table:name=[\'\"]([a-zA-Z0-9_.-]+)[\'\"][^>]*>')
        #                                       table begin tag   name attribute     name
        self.xlsx_special_regex = re.compile('<(autoFilter|mergeCell) [^>]*ref="([^"]+)"[^>]*>')
        #                                   <   autoFilter|mergeCell       ref="       "     >

    def set_string_file(self, string_file):
        self.string_file = string_file
        
    def scan(self, in_file, in_target_file, filename):
        '''reset so that a new set of chunk process actions can begin.'''
        self.in_target_file = in_target_file
        self.in_file_name = filename
        self.target_table_num = self.app.table
        self.namespace_start = ""
        self.namespace_end = ""
        self.table_name = None
        self.table_num = 0
        self.table_depth = 0
        self.row_depth = 0
        self.row_num = 0
        self.in_row = False
        self.row_string = ""
        self.data_row_index = 0
        self.outgoing_data_row_index = 0
        self.flush = False
        if isinstance(self.app.table, str):
            self.target_table_name = self.app.table
        else:
            self.target_table_num = self.app.table
        if self.app.doctype == 'ods' and self.target_table_name is None:  # scan just for target table name
            in_file.seek(0)
            self.file_chunk_feeder.feed(in_file, self.scan_table_names)  # this will set self.target_table_name
            self.csv_merge_processor.formula_adjuster.set_target_table_name(self.target_table_name)
            self.table_num = 0
        elif self.app.doctype == 'xlsx' and self.target_table_name is None and self.target_table_num in self.table_index:
            self.target_table_name = self.table_index[self.target_table_num]
            self.csv_merge_processor.formula_adjuster.set_target_table_name(self.target_table_name)
        if self.app.doctype == 'html' and self.target_table_name:
            regex_string = re.sub(r'id=', ''.join(['id=[\'\"]',self.target_table_name,'[\'\"]']), self.model.tag_regex())
        else:
            regex_string = self.model.tag_regex()
        self.tag_regex = re.compile(regex_string)  # target pattern needs to be a regex-OR pattern that will match either start or end tags
        self.out_file = TemporaryFile(max_size=self.max_buffer)
        self.file_chunk_feeder.feed(in_file, self.chunk_process)
        self.out_file.seek(0)
        return self.out_file
        
    def chunk_process(self, chunk, end_of_file=False):
        '''scan a chunk and identify rows. self.row_string is used to carry partial rows to the next run'''
        if self.app.doctype != 'xlsx':
            chunk = self.special_strings.replace(chunk)
        if self.flush:
            self.write_output(chunk)
            return ("", True)
        process_point = 0 # the point in chunk that has already been sent to out_file
        max_match = 0     # the end of the last found match in this chunk
        row_start = 0     # the start point of a row
        id_match = None   # match of id attribute in html table tag
        overlap_point = len(chunk) - self.overlap_length  #
        for tag in self.tag_regex.finditer(chunk):
            # count the table and row matches
            if tag.group(self.ROWSTART):
                self.row_depth += 1
                if self.row_depth == 1:
                    row_start = tag.start(self.ROWSTART)
                    if self.table_depth == 1:
                        self.row_num += 1
                self.in_row = True
                max_match = tag.end(self.ROWSTART)
                if row_start > process_point:
                    self.write_output(chunk[process_point:row_start])
                    process_point = row_start
            elif tag.group(self.ROWEND):
                row_end = tag.end(self.ROWEND)
                max_match = row_end
                if self.row_depth == 1:
                    self.row_string = ''.join([self.row_string, chunk[row_start:row_end]])
                    process_point = row_end
                    self.row_num = self.row_process(self.row_string, self.row_num)  # write to output, replicate row with merged data if target, row_num will be increased by no. or rows added
                    self.in_row = False
                    self.row_depth = 0
                    self.row_string = ""
                elif self.row_depth > 1: 
                    self.row_depth -= 1
                else:  # for some tags, the rowend and tableend tags are the same, this handles that condition.
                    if self.table_depth >= 1:
                        self.table_depth -= 1
            elif tag.group(self.TABLESTART):  
                self.table_depth += 1
                max_match = tag.end(self.TABLESTART)
                if self.table_depth == 1: 
                    self.table_num +=1
                    self.row_num = 0
                    if self.table_name_attrib_name:
                        id_match = re.search(self.table_name_attrib_name+"=[\'\"]([a-zA-Z_.-]+)[\'\"]", tag.group())
                        if id_match:
                            self.table_name = id_match.group(1)
                            if self.target_table_name is None and self.table_num == self.target_table_num:
                                self.target_table_name = self.table_name
                                self.csv_merge_processor.formula_adjuster.target_table_name = self.table_name
                        else:
                            self.table_name = None
                    elif self.app.doctype == 'xlsx':
                        self.table_name = self.table_index[self.table_num]
                    # check if this is table 1
                    self.in_table_1 = self.table_num == 1 and (self.in_file_name in ('content.xml', 'xl/worksheets/sheet1.xml', 'word/document.xml') or self.app.doctype == 'html') 
                    if self.in_table_1 and self.table_name:
                        self.csv_merge_processor.formula_adjuster.table_1_name = self.table_name
                    # check if this is target table
                    if self.app.doctype == 'xlsx':
                        self.in_target_table = self.in_target_file
                    else:
                        self.in_target_table = self.in_target_file and (
                            (self.target_table_num is not None and self.table_num == self.target_table_num) 
                            or (self.target_table_name is not None and self.table_name == self.target_table_name))
            elif tag.group(self.TABLEEND):
                if self.table_num == self.target_table_num and self.row_num < self.app.target_row:  # the target table had fewer than target rows, process a blank row
                    self.row_num += 1
                    while self.row_num <= self.app.target_row:
                        self.row_process(self.model.row_prototype(), self.row_num)
                        self.row_num += 1
                self.table_depth -= 1
                max_match = tag.end(self.TABLEEND)
                if self.table_depth == 0:
                    self.row_depth = 0
                    self.row_num = 0
                if self.table_num == self.target_table_num and (
                    not self.row_string and self.app.doctype in ['odt', 'html-table', 'html-div', 'docx']):
                    self.flush = True  # the doc types do not need any more row processing
            elif tag.group(self.NAMESPACE):  # the namespace is added to template row before parsing.
                self.namespace_start = tag.group(self.NAMESPACE)
                self.namespace_end = ''.join(["</", tag.group(self.NAMESPACE_TAGNAME), ">"])
        if self.app.doctype == 'xlsx':  # scan for cell merge tags
            for match in self.xlsx_special_regex.finditer(chunk):
                adjusted_ref = self.csv_merge_processor.formula_adjuster.adjust_formula(match.group(2), self.in_table_1, self.in_target_table)
                tag = match.group()
                adjusted_tag = tag.replace(match.group(2), adjusted_ref)
                chunk = chunk.replace(tag, adjusted_tag)
        if end_of_file or self.flush:
            self.write_output(chunk[process_point:])
            process_point = len(chunk)
        elif self.in_row:
            if row_start <= overlap_point:
                self.row_string = ''.join([self.row_string, chunk[row_start:overlap_point]])
                process_point = overlap_point
            else:
                self.row_string = ''.join([self.row_string, chunk[row_start:max_match]])
                process_point = max_match
        else:
            if overlap_point < max_match:
                overlap_point = max_match
            if process_point < overlap_point:
                self.write_output(chunk[process_point:overlap_point])
                process_point = overlap_point
        return (chunk[process_point:], True)

    def row_process(self, row, sheet_row_num):
        '''process a row in different ways depending on row number; send of self.out_file; replicate target row and inject data'''
        if self.in_table_1 and not self.seen_row_1:  # row 1 - check for options in first cell
            row_dom = xml.dom.minidom.parseString(''.join([self.namespace_start, row, self.namespace_end]))
            for cell_tagname in self.model.cell_tagname():
                cell_list = row_dom.getElementsByTagName(cell_tagname)
                if cell_list:
                    cell = cell_list[0]
            if self.textnode_tagname:
                textnode_list = cell.getElementsByTagName(self.textnode_tagname)
                if textnode_list:
                    cell_data = textnode_list[0].firstChild.data
                else:
                    cell_data = ""
            else:
                cell_data = cell.firstChild.data
            if self.app.doctype == 'xlsx':
                if cell_data and cell.hasAttribute('t') and cell.getAttribute('t') == 's':
                    try:
                        index = int(cell_data)
                        cell_data = self.string_file.cell1(index)
                    except ValueError:
                        pass
                else:  # there is no data in cell1
                    self.string_file.cell1(None)  # do the search for cell1 anyway to correctly initialize string_file
            if cell_data[:8].lower() == 'csv2odf:':
                self.app.add_args(cell_data[8:])
                self.app.test_args()  # args in file, verify all args are sufficient
                self.target_table_num = self.app.table  # options may have changed, so reload them
                row = ""  # do not output the row when it has options
                self.app.option_row_offset -= 1
                sheet_row_num = 0
            else:
                self.app.test_args()  # no args in file, verify command line args are sufficient
            if self.app.nodata:
                self.csv_data = None
                self.num_insert_rows = 0
            else:
                self.csv_data = IncomingDataSource(self.app)
                if self.app.end and self.csv_data.num_rows > self.app.end:
                    self.num_insert_rows = self.csv_data.num_rows - self.app.start - (self.csv_data.num_rows - self.app.end) + 1
                else:
                    self.num_insert_rows = self.csv_data.num_rows - self.app.start + 1
            self.csv_merge_processor.set_num_insert_rows(self.num_insert_rows)
            self.seen_row_1 = True
        if self.in_target_table:  # target table
            if sheet_row_num == self.app.target_row - 1:  # the head row
                row_dom = xml.dom.minidom.parseString(''.join([self.namespace_start, row, self.namespace_end]))
                if self.app.header_from_csv:
                    head_row = self.csv_data.next()
                    if head_row:  # merge header row from csv
                        self.csv_merge_processor.set_template(row_dom)
                        row_dom = self.csv_merge_processor.merge_row(head_row, sheet_row_num, self.data_row_index, self.in_table_1, self.in_target_table)
                        row = row_dom.toxml()
                        self.data_row_index += 1
                    else:
                        self.csv_merge_processor.adjust_row(row_dom, self.in_table_1, self.in_target_table)
                        row = row_dom.firstChild.firstChild.toxml()
                else:
                    self.csv_merge_processor.adjust_row(row_dom, self.in_table_1, self.in_target_table)
                    if row_dom.hasChildNodes():
                        if row_dom.firstChild.hasChildNodes():
                            row = row_dom.firstChild.firstChild.toxml()
                        else:
                            row = row_dom.firstChild.toxml()
                    else:
                        row = row_dom.toxml()
                self.write_output(row)
            elif sheet_row_num == self.app.target_row and self.csv_data:  # target row - use this as a template and inject each data row, replicating the template
                row_dom = xml.dom.minidom.parseString(''.join([self.namespace_start, row, self.namespace_end]))
                if self.csv_data.num_rows > 0:
                    self.csv_merge_processor.set_template(row_dom)
                    for data_row in self.csv_data:
                        if self.data_row_index + 1 >= self.app.start and (self.app.end is None or self.data_row_index <= self.app.end):
                            row_dom = self.csv_merge_processor.merge_row(data_row, sheet_row_num, self.outgoing_data_row_index, self.in_table_1, self.in_target_table, True)
                            if app.verbose and self.data_row_index % 5 == 4:
                                sys.stderr.write("csv2odf: processing row " + str(self.data_row_index + 1) + "\r")
                            row = row_dom.toxml()
                            self.write_output(row)
                            self.outgoing_data_row_index += 1
                            sheet_row_num += 1
                        self.data_row_index += 1
                        if self.app.end and self.data_row_index >= self.app.end:
                            break
                    sheet_row_num -= 1  # subtract 1 because the 1st row merged already existed
                else:
                    row_dom = self.csv_merge_processor.null_row(sheet_row_num, self.data_row_index)
                    self.csv_merge_processor.adjust_row(row_dom, self.in_table_1, self.in_target_table, True)
                    row = row_dom.toxml()
                    self.write_output(row)
                if app.verbose:
                    sys.stderr.write("csv2odf: processed " + str(self.data_row_index - self.app.start + 1) + " rows\r\n")
            elif row:  # not target row, but in target table
                row_dom = xml.dom.minidom.parseString(''.join([self.namespace_start, row, self.namespace_end]))
                self.csv_merge_processor.adjust_row(row_dom, self.in_table_1, self.in_target_table, False, self.outgoing_data_row_index)
                row = row_dom.firstChild.firstChild.toxml()
                self.write_output(row)
        elif row:  # not target table
            if self.app.doctype in ['ods', 'xlsx']:
                row_dom = xml.dom.minidom.parseString(''.join([self.namespace_start, row, self.namespace_end]))
                self.csv_merge_processor.adjust_row(row_dom, self.in_table_1, self.in_target_table)
                row = row_dom.firstChild.firstChild.toxml()
            self.write_output(row)
        return sheet_row_num
    
    def write_output(self, data):
        if sys.version_info[0] == 2:
            if isinstance(data, unicode):
                self.out_file.write(data.encode('UTF-8'))
            else:
                self.out_file.write(data)
        else:
            self.out_file.write(bytes(data, 'UTF-8'))
            
    def scan_table_names(self, chunk, end_of_file=False):
        '''Find target table name in a ods document.  <table:table table:name="Reference"> '''
        match = None
        for match in self.ods_table_name_regex.finditer(chunk):
            self.table_num += 1
            if self.table_num == self.target_table_num:
                self.target_table_name = match.group(1)
                break
        if end_of_file:
            overlap = ""
        else:
            overlap_point = len(chunk) - self.overlap_length
            if match and overlap_point < match.end():
                overlap_point = match.end()
            overlap = chunk[overlap_point:]
        return (overlap, self.target_table_name is None)

    def load_sheet_index(self, index_file):
        '''for xlsx, load the index with spreadsheet names'''
        index_file_dom = xml.dom.minidom.parseString(index_file.read())
        for element in index_file_dom.getElementsByTagName('sheet'):
            if element.hasAttribute('name') and element.hasAttribute('sheetId'):
                self.table_index[int(element.getAttribute('sheetId'))] = element.getAttribute('name')
            
    # end class DocumentProcessor


class SharedStringFile:
    '''For xlsx files, read existing file and append strings, return extended file'''
    
    in_file = None           # a file object
    out_file = None          # a file object
    special_strings = None   # an object that can replace special string
    max_buffer = 20e6        # the maximum memory size used before the buffer is written to disk
    chunk_size = 4096        # the size of each chunk
    overlap_length = 64      # the max amount of overlap to return
    chunk1 = None            # the first chunk
    num_found_cells = 0      # the number of cells found
    cell1_index = None       # the index of cell1 to search for
    cell1_string = ""        # the found cell1
    inserted = 0             # the number of strings added to the original list
    cell_regex = None        # regex to find cell contents
    date_regex = None        # regex to find date tags
    STRING_START = "<si><t>" # string start tag
    STRING_END = "</t></si>" # string end tag
    LIST_END = "</sst>"      # end of list tag
    date_cell_index_list = [] # list of cell indexes tagged as dates for csv2odf
    debug = False            # turn on extra information
    
    def __init__(self, in_file, special_string_replacement_object, debug):
        self.in_file = in_file
        self.special_strings = special_string_replacement_object
        self.intermediate_file = TemporaryFile(max_size=self.max_buffer)
        self.out_file = TemporaryFile(max_size=self.max_buffer)
        self.cell_regex = re.compile("(<si><t>)([^<>]*)(</t></si>)|(</sst>)")
        #                             1 start 2 string 3 end str   4 end of list
        self.date_regex = re.compile(r"\[csv2odf-date[^\]]*\]", re.IGNORECASE)
        self.debug = debug
        
    def cell1(self, cell1_index):
        '''load string file and scan for cell1 and date cells, return cell1 '''
        self.cell1_index = cell1_index
        file_chunk_feeder = SequentialChunkFeeder()
        file_chunk_feeder.feed(self.in_file, self.scan_chunk_cells)
        self.in_file.close()
        return self.cell1_string
    
    def scan_chunk_cells(self, chunk):
        '''check for date cells and cell1 data'''
        for match in self.cell_regex.finditer(chunk):
            if match.group(2):
                if self.date_regex.search(match.group(2)):  # found date tag
                    self.date_cell_index_list.append(self.num_found_cells)  # store the index of the date cell
                if self.num_found_cells == self.cell1_index:  # found cell1
                    self.cell1_string = match.group(2)
                self.num_found_cells += 1
        if match.group(4):  # the end of string list, do not write out the end tag at this time.
            self.write_intermediate(self.special_strings.replace(chunk[:match.start()]))
            return ("", False)
        else:
            overlap_point = len(chunk) - self.overlap_length
            if match and match.end() > overlap_point:
                overlap_point = match.end()
            self.write_intermediate(self.special_strings.replace(chunk[:overlap_point]))
            return (chunk[overlap_point:], True)
    
    def is_a_date_cell(self, index_string):
        try:
            return int(index_string) in self.date_cell_index_list
        except ValueError:
            return False
        
    def append(self, string):
        self.num_found_cells += 1
        self.inserted += 1
        if self.debug:
            sys.stderr.write("string "+str(self.num_found_cells-1)+": "+string+"\n")
        self.write_intermediate(''.join([self.STRING_START, cgi.escape(string), self.STRING_END]))
        return self.num_found_cells-1
        
    def finish(self):
        '''end the string file and update count and unique_count attributes.'''
        self.write_intermediate(self.LIST_END)
        # read first chunk and replace count
        self.intermediate_file.seek(0)
        if sys.version_info[0] == 2:
            chunk = str(self.intermediate_file.read(self.chunk_size))
        else:
            chunk = self.intermediate_file.read(self.chunk_size).decode('UTF-8')
        count_regex_string = '(<sst[^>]*count=[\"\'])([0-9]+)([\"\'][^>]*>)'
        #                     (<sst  *  count=      )(number)(     *     >)
        #                            group 1          group 2    group 3
        count_regex = re.compile(count_regex_string)
        match = count_regex.search(chunk)
        count = int(match.group(2))
        chunk = count_regex.sub(''.join([match.group(1), str(count + self.inserted), match.group(3)]), chunk)
        count_regex_string = '(<sst[^>]*uniqueCount=[\"\'])([0-9]+)([\"\'][^>]*>)'
        #                     (<sst  *  uniqueCount=      )(number)(     *     >)
        #                            group 1                group 2    group 3       
        unique_count_regex = re.compile(count_regex_string)
        match = unique_count_regex.search(chunk)
        unique_count = int(match.group(2))
        chunk = unique_count_regex.sub(''.join([match.group(1), str(unique_count + self.inserted), match.group(3)]), chunk)
        #write the first chunk to out_file
        if sys.version_info[0] == 2:
            if isinstance(chunk, unicode):
                self.out_file.write(chunk.encode('UTF-8'))
            else:
                self.out_file.write(chunk)
        else:
            self.out_file.write(bytes(chunk, 'UTF-8'))
        #read remaining data from intermediate_file and write out
        self.out_file.write(self.intermediate_file.read())
        self.intermediate_file.close()
        return self.out_file
        
    def write_intermediate(self, data):
        if sys.version_info[0] == 2:
            if isinstance(data, unicode):
                self.intermediate_file.write(data.encode('UTF-8'))
            else:
                self.intermediate_file.write(data)
        else:
            self.intermediate_file.write(bytes(data, 'UTF-8'))

    # end class SharedStringFile


class SpecialStringSubstitutionProcessor:
    '''Searches for a date tag like [date]
    or a date tag with a format like [date %Y-%m-%d]
    or a date tag with an offset like [date-1] in days
    and replaces it with the local date.
    Also search for [csv2odf-comment] and replace with self.comment.'''

    replace_comment = False # turns off the replacement comment operation if there is not comment
    do_replacements = True  # turns off the replacement operation if not needed
    comment = ""            # a string supplied by the user to be inerted into the document
    comment_regex = None    # compiled regex for comment
    date_regex = None       # compiled regex for date
    
    def __init__(self, comment=""):
        if comment:
            self.replace_comment = True
            self.comment = comment
        self.comment_regex = re.compile("\[csv2odf-comment\]", re.IGNORECASE)
        self.date_regex = re.compile("\[csv2odf-date([ ]{0,1})([^\]]*)\]", re.IGNORECASE)
        #                              [csv2odf-date           format  ]

    def replace(self, string):
        if string is None:
            return None
        if self.replace_comment:
            string = self.comment_regex.sub(self.comment, string) # replace '[csv2odf-comment]' with comment
        if self.do_replacements:
            for match in self.date_regex.finditer(string):
                date_spec = match.group(2)
                if date_spec.startswith("+") or date_spec.startswith("-"):
                    # there will be a date offset
                    end_of_offset = date_spec.find(" ", 1)
                    if end_of_offset == -1:
                        end_of_offset = len(date_spec)
                    try:
                        offset = datetime.timedelta(float(date_spec[0:end_of_offset]))
                        date_spec = date_spec[end_of_offset:]
                    except ValueError:
                        # the string cannot be interpreted, assume it should be part of the date format and not an offset
                        offset = datetime.timedelta(0)
                    display_date = datetime.datetime.today()+offset
                else:  
                    display_date = datetime.datetime.today()
                if not date_spec:
                    date_spec = "%Y-%m-%d"
                date_string = display_date.strftime(date_spec)
                string = string.replace(match.group(), date_string) # replace '[csv2odf-comment]' with self.app.comment
        return string
    
    # end class SpecialStringSubstitutionProcessor


class TemporaryFile:
    '''Like SpooledTemporaryFile, this will reside in memory until it reaches
       a size limit or until a rollover command is received.
       Unlike SpooledTemporaryFile, it will have a filename when it becomes a disk file.'''

    name = None
    ram_file = None
    disk_file = None
    is_open = False
    mode = 'w+b'
    is_in_ram = True
    size_limit = 20E6
    chunk_size = 0x10000
    
    def __init__(self, max_size=None, mode='w+b'):
        self.mode = mode
        if max_size:
            self.size_limit = max_size
        if mode == 'w':
            self.ram_file = io.StringIO()
        else:
            self.ram_file = io.BytesIO()
        
    def read(self, number_of_bytes=None):
        if self.is_in_ram:
            return self.ram_file.read(number_of_bytes)
        else:
            if number_of_bytes:
                return self.disk_file.read(number_of_bytes)
            else:
                return self.disk_file.read()
    
    def __iter__(self):
        return self

    def next(self):  # used by python 2.x
        return self.__next__()
          
    def __next__(self):
        if self.is_in_ram:
            if self.mode == 'w':
                line = self.ram_file.readline()
                if line:
                    return line
                else:
                    raise StopIteration
            else:
                return self.ram_file.__next__()
        else:
            return self.disk_file.__next__()
          
    def write(self, data):
        if self.is_in_ram:
            self.ram_file.write(data)
            if self.ram_file.tell() > self.size_limit:
                self.rollover()
        else:
            self.disk_file.write(data)
    
    def seek(self, position, start_point=0):
        if self.is_in_ram:
            return self.ram_file.seek(position, start_point)
        else:
            return self.disk_file.seek(position, start_point)
    
    def is_in_ram(self):
        return self.is_in_ram
    
    def tell(self):
        if self.is_in_ram:
            return self.ram_file.tell()
        else:
            return self.disk_file.tell()
          
    def flush(self):
        if self.is_in_ram:
            return self.ram_file.flush()
        else:
            return self.disk_file.flush()
          
    def rollover(self):
        self.disk_file = tempfile.NamedTemporaryFile()
        self.name = self.disk_file.name
        self.ram_file.seek(0)
        self.disk_file.write(self.ram_file.read())
        self.is_in_ram = False
        self.ram_file.close()
    
    def write_to_zipfile(self, inner_filename, zipfile):
        if self.is_in_ram:
            zipfile.writestr(inner_filename, self.ram_file.read())
        else:
            zipfile.write(self.name, inner_filename)
    
    def close(self):
        if self.is_in_ram:
            self.ram_file.close()
        else:
            self.disk_file.close()

    # end class TemporaryFile


class DocumentArchive:
    '''Allows opening a zip archive, filenames matching a regex pattern are loaded from the archive into temporary files, new temporary files with altered content can replace old ones when the archive is rewritten to a new filename.'''
    
    #properties
    app = None
    type = 'zip'
    in_package_name = None
    in_package_file = None
    inner_filenames = None  # list of all filenames in the zip file
    target_filename_pattern = None
    target_filename = None
    fileobject_list = dict()  # dictionary of file objects with file names as keys
    max_buffer = 20e6
    
    def __init__(self, app, model):
        self.app = app
        if self.app.doctype == 'xlsx':
            self.target_filename_pattern = model.target_filename_regex().replace("[0-9]", str(app.table))
        else:
            self.target_filename_pattern = model.target_filename_regex()
        
    def open(self, in_package_name):
        '''open in file and out file.  If in file is stdin, load it into a temporary file.
            If any error, return a message, otherwise return null'''
        self.in_package_name = in_package_name
        if self.in_package_name == "stdin":
            if sys.stdin.isatty():
                self.app.stop("Error: there was no template file specified.")
            else:
                t = TemporaryFile(max_size=self.max_buffer)
                if sys.version_info[0] == 2:
                    t.write(bytes(sys.stdin.read()))
                else:
                    t.write(bytes(sys.stdin.buffer.read()))
                t.seek(0)
                try:
                    self.in_package_file = zipfile.ZipFile(t,'r')
                    self.inner_filenames = self.in_package_file.namelist()
                except zipfile.BadZipfile:  # it's not zip, assume it's html
                    self.in_package_file = t
                    self.in_package_file.seek(0)
                    self.inner_filenames = ["stdin"]
                    self.type = 'html'
                except IOError:
                    self.app.stop("Error: there was an error while reading template from stdin.")
        else:
            try:
                self.in_package_file = zipfile.ZipFile(self.in_package_name,'r')
                self.inner_filenames = self.in_package_file.namelist()
            except zipfile.BadZipfile:  # it's not zip, assume it's html
                self.in_package_file = open(self.in_package_name,'r')
                self.inner_filenames = [self.in_package_name]
                self.type = 'html'
        
    def read(self, filename_regex):
        '''read file(s) from package into temporary files'''
        if self.type == 'zip':
            for inner_filename in self.in_package_file.namelist():
                match = re.match(filename_regex, inner_filename)
                if match:
                    if inner_filename not in self.fileobject_list:  # this is a new request, else ignore
                        self.fileobject_list[inner_filename] = TemporaryFile(max_size=self.max_buffer)         
                        self.fileobject_list[inner_filename].write(self.in_package_file.read(inner_filename))
                        self.fileobject_list[inner_filename].seek(0)
                        if re.match(self.target_filename_pattern, inner_filename):
                            self.target_filename = inner_filename
        else:
            self.target_filename = self.in_package_name
            if not filename_regex:
                filename_regex = self.in_package_name
            if filename_regex not in self.fileobject_list:  # if it's already in the list, don't reopen
                self.fileobject_list[filename_regex] = TemporaryFile(max_size=self.max_buffer)  
                self.fileobject_list[filename_regex].seek(0)
                if sys.version_info[0] == 2:
                    self.fileobject_list[filename_regex].write(bytes(self.in_package_file.read()))
                else:
                    if self.type == 'html':
                        incoming_data = self.in_package_file.read()
                        if type(incoming_data) == type('string'):
                            incoming_data = bytes(incoming_data, 'UTF-8')
                        self.fileobject_list[filename_regex].write(incoming_data)
                    else:
                        self.fileobject_list[filename_regex].write(self.in_package_file.read())
                self.fileobject_list[filename_regex].seek(0)
    
    def all_zip_names(self):
        return self.inner_filenames
    
    def loaded_files(self):
        return self.fileobject_list
    
    def prioritized_filename_list(self):
        '''set the order of files for specific document types'''
        filename_list = list(self.fileobject_list.keys())
        if self.app.doctype == 'ods' and 'content.xml' in filename_list:  # put content.xml in 1st position
            target_index = filename_list.index('content.xml')
            filename_list[0], filename_list[target_index] = filename_list[target_index], filename_list[0]
        elif self.app.doctype == 'xlsx' and 'xl/worksheets/sheet1.xml' in filename_list:
            target_index = filename_list.index('xl/worksheets/sheet1.xml')
            filename_list[0], filename_list[target_index] = filename_list[target_index], filename_list[0]
        return filename_list
    
    def set_target_filename(self, filename):
        self.target_filename = filename
    
    def get_target_file(self):
        if self.target_filename in self.fileobject_list:
            return self.fileobject_list[self.target_filename]
        else:
            return None
        
    def inner_file_object(self, filename):
        if filename in self.fileobject_list:
            return self.fileobject_list[filename]
        else:
            return None
        
    def replace_file_object(self, filename, file_object):
        if filename in self.fileobject_list:
            self.fileobject_list[filename].close()
        self.fileobject_list[filename] = file_object
        
    def save(self, out_file_name):
        '''save the fileobject_list or original files into a new zip file.'''
        error_message = "No files inserted."
        if out_file_name == "stdout":  # send the output to stdout
            buffer = TemporaryFile(max_size=self.max_buffer)
            if self.type == 'zip':
                outputfile = zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED)
            else:
                outputfile = buffer
        else:  # send the output to a file
            try:
                if self.type == 'zip':
                    outputfile = zipfile.ZipFile(out_file_name,'w', zipfile.ZIP_DEFLATED)
                else: # html
                    outputfile = open(out_file_name,'w')
            except Exception:
                self.app.stop("Error opening output: " + out_file_name)
        try:
            if self.type == 'zip':
                for name in self.in_package_file.namelist():
                    if name in self.fileobject_list:  #write the modified file to output
                        self.fileobject_list[name].seek(0)
                        if self.fileobject_list[name].is_in_ram:
                            outputfile.writestr(name, self.fileobject_list[name].read())
                        else:
                            outputfile.write(self.fileobject_list[name].name, name)
                        self.fileobject_list[name].close()
                        error_message = None
                    elif name == "mimetype":  # write the mimetype file to output, it is the 1st file and uncompressed
                        mimetype_info = self.in_package_file.getinfo("mimetype")  # this saves the compression type of mimetype (stored) so that it will be saved the same type of compression
                        outputfile.writestr(mimetype_info, self.in_package_file.read(name))
                    else:  # write all other files to output without modification
                        outputfile.writestr(name, self.in_package_file.read(name))
                outputfile.close()
            else:  
                file = self.fileobject_list[self.in_package_name]
                if file:
                    file.seek(0)
                    self.write_output(file, outputfile)
                    error_message = None
        finally:
            if out_file_name == "stdout":
                buffer.seek(0)
                if sys.version_info[0] == 2:
                    sys.stdout.write(buffer.read())
                else:
                    try:
                        sys.stdout.buffer.write(buffer.read())
                    except TypeError:
                        buffer.seek(0)
                        sys.stdout.write(buffer.read())
            outputfile.close()
            self.in_package_file.close()
        self.app.warning(error_message)
    
    def direct_save(self, file):
        file.seek(0)
        if self.app.out_filename == "stdout":  # send the output to stdout
            if sys.version_info[0] == 2:
                sys.stdout.write(file.read())
            else:
                try:
                    sys.stdout.buffer.write(file.read())
                except TypeError:
                    file.seek(0)
                    sys.stdout.write(file.read())
        else:  # send the output to a file
            try:
                outputfile = open(self.app.out_filename,'wb')
            except Exception:
                self.app.stop("Error opening output: " + self.app.out_filename)
            self.write_output(file, outputfile)

    def write_output(self, in_file, out_file):
        if sys.version_info[0] == 2:
            if in_file.__class__.__name__ == 'TemporaryFile':
                out_file.write(in_file.read())
            else:
                out_file.write(in_file.read().decode('UTF-8'))
        else:
            if isinstance(out_file, io.TextIOWrapper):
                out_file.write(in_file.read().decode('UTF-8'))
            else:
                out_file.write(bytes(in_file.read().decode('UTF-8'), 'UTF-8'))
            
    # end class DocumentArchive


class IncomingDataSource:

    #properties
    app = None
    type = None
    buffer = []
    inputfile = None
    reader = None
    num_rows = 0
    num_columns = 0
    max_buffer = 20e6

    def __init__(self, app):
        self.app = app
        self.open(self.app.csv_filename)

    def open(self, filename):
        '''Prepare a csv file for reading.'''
        import csv
        if filename == "stdin":
            if sys.stdin.isatty():
                self.app.stop("Error: there was no template file specified.")
            else:
                self.inputfile = TemporaryFile(self.max_buffer, 'w')  # inputfile needs to be seekable, so load stdin to a tempfile
                if sys.version_info[0] == 2:
                    self.inputfile.write(sys.stdin.read().decode('UTF-8'))
                else:
                    self.inputfile.write(sys.stdin.buffer.read().decode('UTF-8'))
                self.inputfile.seek(0)
        else:
            if sys.version_info[0] == 2:
                self.inputfile = open(filename,'r')
            else:
                self.inputfile = open(filename, 'r', newline='')
        self.reader = csv.reader(self.inputfile, delimiter=self.app.delimiter)
        self.profile()
    
    def profile(self):
        '''Scan over the csv file and find the number of rows and the length of the longest line.'''
        for row in self:
            self.num_rows += 1
            num_columns = 0
            for column in row:
                num_columns += 1
            if num_columns > self.num_columns:
                self.num_columns = num_columns
        self.inputfile.seek(0)

    def __iter__(self):
        return self

    def next(self):  # used by python 2.x
        return self.__next__()
          
    def __next__(self):
        if not self.reader:
            raise StopIteration
        if sys.version_info[0] == 2:
            return self.reader.next()
        else:
            return self.reader.__next__()
          
    def close(self):
        if self.inputfile is not None:
            self.inputfile.close()

    # end class IncomingDataSource


if __name__ == "__main__":
    app = ApplicationController()
    model = DocumentModel(app)
    zip = DocumentArchive(app, model)
    special_strings = SpecialStringSubstitutionProcessor(app.comment)
    csv_merge_processor = CSVMergeProcessor(app, model)
    document_processor = DocumentProcessor(app, model, csv_merge_processor, special_strings)
    zip.open(app.template_filename)
    zip.read(model.inner_filename_regex())
    if app.doctype == 'xlsx':
        string_file = SharedStringFile(zip.inner_file_object('xl/sharedStrings.xml'), special_strings, app.debug)
        csv_merge_processor.set_string_file(string_file)
        document_processor.set_string_file(string_file)
        document_processor.load_sheet_index(zip.inner_file_object('xl/workbook.xml'))
    if app.xml:
        zip.direct_save(document_processor.scan(zip.get_target_file(), True, zip.target_filename))
    else:
        for filename in zip.prioritized_filename_list():
            if app.debug:
                sys.stderr.write("processing file: "+filename+"\n")
            if app.doctype == 'html' or re.match(zip.target_filename_pattern, filename):  # process only target in this loop
                replacement = document_processor.scan(zip.inner_file_object(filename), True, filename)
                zip.replace_file_object(filename, replacement)
            elif filename != 'xl/sharedStrings.xml': 
                replacement = document_processor.scan(zip.inner_file_object(filename), False, filename)
                zip.replace_file_object(filename, replacement)
        if app.doctype == 'xlsx':
            zip.replace_file_object('xl/sharedStrings.xml', string_file.finish())
        zip.save(app.out_filename)


